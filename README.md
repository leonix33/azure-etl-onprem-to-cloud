# Azure ETL Project: On-Premise to Cloud

[![Terraform](https://img.shields.io/badge/Terraform-1.0+-purple.svg)](https://www.terraform.io/)
[![Azure](https://img.shields.io/badge/Azure-Cloud-blue.svg)](https://azure.microsoft.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A complete end-to-end ETL (Extract, Transform, Load) solution for migrating data from on-premise systems to Azure Cloud using Azure Data Factory, Self-Hosted Integration Runtime, Key Vault, and Azure SQL Database.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ON-PREMISE ENVIRONMENT                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  File System  â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Windows VM (SHIR)   â”‚            â”‚
â”‚  â”‚  (CSV Files)  â”‚         â”‚  Self-Hosted IR      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚ Secure Connection
                                     â”‚ (HTTPS)
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AZURE CLOUD                                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Key Vault     â”‚â—€â”€â”€â”€â”€â”‚  Data Factory       â”‚               â”‚
â”‚  â”‚  (Secrets)     â”‚      â”‚  - Pipelines        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  - Datasets         â”‚               â”‚
â”‚                          â”‚  - Linked Services  â”‚               â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                    â”‚                            â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                   â–¼                                  â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Blob Storage (Data Lake)  â”‚    â”‚  Azure SQL Database   â”‚  â”‚
â”‚  â”‚  - raw-data                â”‚    â”‚  - Employees Table    â”‚  â”‚
â”‚  â”‚  - processed-data          â”‚    â”‚  - Analytics Views    â”‚  â”‚
â”‚  â”‚  - archive-data            â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Features

- **Self-Hosted Integration Runtime (SHIR)**: Secure connection between on-premise and cloud
- **Azure Key Vault**: Centralized secrets management for credentials
- **Azure Data Factory**: Orchestration of ETL pipelines
- **Azure Blob Storage**: Data Lake for raw, processed, and archived data
- **Azure SQL Database**: Target database for transformed data
- **Infrastructure as Code**: Complete Terraform automation
- **Auto-Shutdown**: Cost optimization with VM auto-shutdown
- **Secure by Default**: Network security groups, private endpoints, managed identities

## ğŸ“‹ Prerequisites

- Azure CLI (`az`) installed and configured
- Terraform 1.0 or higher
- Active Azure subscription
- macOS/Linux terminal or Windows PowerShell
- RDP client for Windows VM access

## ğŸš€ Quick Start

### 1. Clone and Navigate

```bash
cd /Users/user/Desktop/Development/azure-etl-project
```

### 2. Review Configuration

Edit [terraform/variables.tf](terraform/variables.tf) to customize:
- Resource names
- Azure region
- VM size
- Tags

### 3. Deploy Infrastructure

```bash
./scripts/deploy.sh
```

This will:
- âœ… Initialize Terraform
- âœ… Create all Azure resources
- âœ… Configure networking and security
- âœ… Set up Key Vault with secrets
- âœ… Deploy Data Factory with SHIR
- âœ… Output connection details

### 4. Configure SHIR on VM

After deployment:

```bash
# Get the SHIR authentication key
./scripts/get-shir-key.sh
```

Then:
1. RDP to the VM (IP shown in deployment output)
2. Download SHIR installer: https://aka.ms/dmg
3. Run PowerShell as Administrator:
   ```powershell
   # Copy the key from get-shir-key.sh output
   .\install-shir.ps1 -AuthKey "YOUR_SHIR_KEY_HERE"
   ```

### 5. Set Up SQL Database

Connect to Azure SQL Database and run:

```bash
# Get SQL connection details
cd terraform
terraform output sql_server_fqdn
terraform output sql_database_name
```

Execute [adf-pipelines/sql_setup.sql](adf-pipelines/sql_setup.sql) to create tables and views.

### 6. Deploy ADF Pipelines

1. Navigate to [Azure Portal](https://portal.azure.com)
2. Open your Data Factory
3. Click "Author & Monitor"
4. Import pipeline definitions from `adf-pipelines/`

### 7. Test the Pipeline

The pipeline will:
1. **Extract**: Read CSV files from on-premise VM
2. **Load**: Copy to Azure Blob Storage (raw-data container)
3. **Transform**: Load into Azure SQL Database
4. **Archive**: Move processed files to archive container

## ğŸ“ Project Structure

```
azure-etl-project/
â”œâ”€â”€ terraform/              # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf            # Main configuration
â”‚   â”œâ”€â”€ variables.tf       # Input variables
â”‚   â”œâ”€â”€ network.tf         # VNet, NSG, Subnets
â”‚   â”œâ”€â”€ vm.tf              # SHIR VM
â”‚   â”œâ”€â”€ keyvault.tf        # Key Vault and secrets
â”‚   â”œâ”€â”€ storage.tf         # Blob Storage
â”‚   â”œâ”€â”€ datafactory.tf     # ADF resources
â”‚   â”œâ”€â”€ sql.tf             # SQL Database
â”‚   â””â”€â”€ outputs.tf         # Output values
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â”œâ”€â”€ deploy.sh          # Deploy infrastructure
â”‚   â”œâ”€â”€ cleanup.sh         # Destroy resources
â”‚   â”œâ”€â”€ get-shir-key.sh    # Get SHIR key
â”‚   â”œâ”€â”€ install-shir.ps1   # Install SHIR on VM
â”‚   â””â”€â”€ monitor.sh         # Monitor resources
â”œâ”€â”€ adf-pipelines/         # Data Factory definitions
â”‚   â”œâ”€â”€ pipeline_onprem_to_cloud_etl.json
â”‚   â”œâ”€â”€ dataset_onprem_csv.json
â”‚   â”œâ”€â”€ dataset_blob_raw.json
â”‚   â”œâ”€â”€ dataset_blob_archive.json
â”‚   â”œâ”€â”€ dataset_sql_employees.json
â”‚   â””â”€â”€ sql_setup.sql
â”œâ”€â”€ sample-data/           # Sample CSV files
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ README.md             # This file
```

## ğŸ’° Cost Management

### Estimated Monthly Costs (24/7 operation)

| Service | Size/SKU | Est. Cost |
|---------|----------|-----------|
| Windows VM | Standard_D2s_v3 | ~$70-90 |
| Storage Account | Standard LRS | ~$2-5 |
| SQL Database | Basic | ~$5 |
| Data Factory | Pay per execution | Variable |
| **Total** | | **~$80-100/month** |

### Cost Optimization

1. **Auto-Shutdown**: VM automatically shuts down at 7 PM daily
2. **Deallocate VM**: When not in use
   ```bash
   az vm deallocate -g rg-azure-etl-project -n <vm-name>
   ```
3. **Monitor Usage**:
   ```bash
   ./scripts/monitor.sh
   ```
4. **Clean Up**: Destroy all resources when done
   ```bash
   ./scripts/cleanup.sh
   ```

## ğŸ” Security Features

- âœ… All credentials stored in Azure Key Vault
- âœ… Managed Identity for Data Factory
- âœ… Network Security Groups for VM
- âœ… Private networking (can be extended)
- âœ… HTTPS-only communication
- âœ… IP whitelisting for Key Vault and SQL
- âœ… Soft delete enabled on Key Vault

## ğŸ”§ Common Operations

### Monitor Resources
```bash
./scripts/monitor.sh
```

### Get VM Password
```bash
az keyvault secret show --vault-name <kv-name> --name vm-admin-password --query value -o tsv
```

### Check SHIR Status
```bash
# In Azure Portal
Data Factory â†’ Manage â†’ Integration Runtimes
```

### Test Pipeline
```bash
# In Azure Portal
Data Factory â†’ Author â†’ Pipelines â†’ OnPrem_to_Azure_ETL_Pipeline â†’ Debug
```

## ğŸ“Š Data Flow

1. **Source**: CSV files in `C:\OnPremiseData` on VM
2. **Landing**: Azure Blob Storage â†’ `raw-data` container
3. **Processing**: Azure Data Factory transformation
4. **Target**: Azure SQL Database â†’ `dbo.Employees` table
5. **Archive**: Azure Blob Storage â†’ `archive-data` container (dated folders)

## ğŸ”„ Pipeline Schedule

The ETL pipeline can be scheduled to run:
- Hourly
- Daily at specific time
- Event-driven (file arrival)
- Manual trigger

Configure in Data Factory â†’ Triggers

## ğŸ› Troubleshooting

### SHIR Not Connecting
- Check VM is running: `./scripts/monitor.sh`
- Verify authentication key: `./scripts/get-shir-key.sh`
- Check firewall rules on VM
- Ensure HTTPS (443) outbound is allowed

### Pipeline Failures
- Check Data Factory Monitor tab
- Verify linked service connections
- Confirm credentials in Key Vault
- Check source files exist

### SQL Connection Issues
- Verify firewall rules include your IP
- Check connection string in Key Vault
- Ensure SQL Database is online

## ğŸ“ Git Integration

### Initialize Local Repository

```bash
cd /Users/user/Desktop/Development/azure-etl-project
git init
git add .
git commit -m "Initial commit: Azure ETL project"
```

### Push to GitHub

```bash
git remote add origin https://github.com/YOUR_USERNAME/azure-etl-project.git
git branch -M main
git push -u origin main
```

### Update Data Factory Git Integration

After pushing to GitHub, update [terraform/datafactory.tf](terraform/datafactory.tf):
- Set your GitHub account name
- Set your repository name
- Redeploy with `./scripts/deploy.sh`

## ğŸ§¹ Cleanup

When you're done with the project:

```bash
./scripts/cleanup.sh
```

This will:
- Destroy all Azure resources
- Remove Terraform state
- Clean up local files

âš ï¸ **Warning**: This is irreversible!

## ğŸ“š Learn More

- [Azure Data Factory Documentation](https://docs.microsoft.com/azure/data-factory/)
- [Self-Hosted Integration Runtime](https://docs.microsoft.com/azure/data-factory/concepts-integration-runtime)
- [Azure Key Vault](https://docs.microsoft.com/azure/key-vault/)
- [Terraform Azure Provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs)

## ğŸ¤ Contributing

This is a personal learning/portfolio project. Feel free to fork and adapt for your own use.

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

Your Name - Azure Cloud Engineer

---

**Built with** â¤ï¸ **using Terraform and Azure**
